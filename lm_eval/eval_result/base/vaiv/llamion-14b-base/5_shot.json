{
  "results": {
    "klue_nli": {
      "acc": 0.477,
      "acc_stderr": 0.009120566223801597
    },
    "klue_sts": {
      "acc": 0.2350674373795761,
      "acc_stderr": 0.018631290224026972,
      "f1": 0.22309197651663404,
      "f1_stderr": 0.02447492566295569
    },
    "klue_ynat": {
      "acc": 0.6876029427912594,
      "acc_stderr": 0.0048568926825005975,
      "macro_f1": 0.6722969594036835,
      "macro_f1_stderr": 0.005468606307570972
    },
    "kobest_boolq": {
      "acc": 0.9123931623931624,
      "acc_stderr": 0.007547987587123646,
      "macro_f1": 0.9123927624039485,
      "macro_f1_stderr": 0.007571353005632075
    },
    "kobest_copa": {
      "acc": 0.787,
      "acc_stderr": 0.012953717566737223,
      "macro_f1": 0.7867677901234444,
      "macro_f1_stderr": 0.012959519884447794
    },
    "kobest_hellaswag": {
      "acc": 0.478,
      "acc_stderr": 0.02236139673920787,
      "acc_norm": 0.564,
      "acc_norm_stderr": 0.022198954641476896,
      "macro_f1": 0.474036516359764,
      "macro_f1_stderr": 0.02228488264141849
    },
    "kobest_sentineg": {
      "acc": 0.9722921914357683,
      "acc_stderr": 0.008248061588744124,
      "macro_f1": 0.9722921914357683,
      "macro_f1_stderr": 0.008284131693538302
    },
    "kohatespeech": {
      "acc": 0.3503184713375796,
      "acc_stderr": 0.02200558149590545,
      "macro_f1": 0.3410367841950301,
      "macro_f1_stderr": 0.02187534103976857
    },
    "kohatespeech_apeach": {
      "acc": 0.7312997347480106,
      "acc_stderr": 0.00722052351690577,
      "macro_f1": 0.7237061192893355,
      "macro_f1_stderr": 0.007348589793081433
    },
    "kohatespeech_gen_bias": {
      "acc": 0.5435244161358811,
      "acc_stderr": 0.022975733044589438,
      "macro_f1": 0.4381190178942988,
      "macro_f1_stderr": 0.021221060610685523
    },
    "korunsmile": {
      "f1": 0.32291097405536623,
      "f1_stderr": 0.007556357678067994
    },
    "nsmc": {
      "acc": 0.86168,
      "acc_stderr": 0.0015439557079089284
    },
    "pawsx_ko": {
      "acc": 0.5615,
      "acc_stderr": 0.011098218786369057
    }
  },
  "versions": {
    "klue_nli": 0,
    "klue_sts": 0,
    "klue_ynat": 0,
    "kobest_boolq": 0,
    "kobest_copa": 0,
    "kobest_hellaswag": 0,
    "kobest_sentineg": 0,
    "kohatespeech": 0,
    "kohatespeech_apeach": 0,
    "kohatespeech_gen_bias": 0,
    "korunsmile": 0,
    "nsmc": 0,
    "pawsx_ko": 0
  },
  "config": {
    "model": "hf-causal-experimental",
    "model_args": "pretrained=vaiv/llamion-14b-base,use_accelerate=true,trust_remote_code=true",
    "num_fewshot": 5,
    "batch_size": "4",
    "device": null,
    "no_cache": true,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}